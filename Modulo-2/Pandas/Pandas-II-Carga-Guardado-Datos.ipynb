{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788e211b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Carga-de-datos\" data-toc-modified-id=\"Carga-de-datos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Carga de datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#pd.read_csv()\" data-toc-modified-id=\"pd.read_csv()-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><code>pd.read_csv()</code></a></span></li><li><span><a href=\"#pd.read_excel()\" data-toc-modified-id=\"pd.read_excel()-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><code>pd.read_excel()</code></a></span></li><li><span><a href=\"#pd.read_json()\" data-toc-modified-id=\"pd.read_json()-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><code>pd.read_json()</code></a></span></li><li><span><a href=\"#pd.read_clipboard()\" data-toc-modified-id=\"pd.read_clipboard()-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><code>pd.read_clipboard()</code></a></span></li><li><span><a href=\"#pd.read_pickle()\" data-toc-modified-id=\"pd.read_pickle()-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span><code>pd.read_pickle()</code></a></span></li><li><span><a href=\"#pd.read_parquet()\" data-toc-modified-id=\"pd.read_parquet()-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span><code>pd.read_parquet()</code></a></span></li><li><span><a href=\"#pd.read_sas()\" data-toc-modified-id=\"pd.read_sas()-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span><code>pd.read_sas()</code></a></span></li><li><span><a href=\"#pd.read_spss()\" data-toc-modified-id=\"pd.read_spss()-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span><code>pd.read_spss()</code></a></span></li></ul></li><li><span><a href=\"#üìå-Nota-importante-al-leer-archivos:\" data-toc-modified-id=\"üìå-Nota-importante-al-leer-archivos:-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>üìå Nota importante al leer archivos</a></span></li><li><span><a href=\"#Guardado-de-datos\" data-toc-modified-id=\"Guardado-de-datos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Guardado de datos</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b107551",
   "metadata": {},
   "source": [
    "Pandas nos va a permitir leer una gran multitud de ficheros con los que podremos trabajar con los m√©todos que aprenderemos en las pr√≥ximas sesiones. En este jupyter vamos a ver algunos de los m√°s usados: \n",
    "\n",
    "- csv\n",
    "- excel\n",
    "- json\n",
    "- clipboard\n",
    "- parquet\n",
    "- pickle\n",
    "- sql\n",
    "- sas\n",
    "- spss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca908d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pero antes de empezar ya sabeis, a importar las librer√≠as que necesitaremos!!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de99dd",
   "metadata": {},
   "source": [
    "üö®üö®üö® **NOTA** importante antes de seguir con esta lecci√≥n. Algunos de los ficheros que necesitaremos para la lecci√≥n de hoy son muy pesados y es imposible compartirlos con vosotras por GitBook. En concreto estos datos ser√°n: \n",
    "\n",
    "- 10M.pkl\n",
    "\n",
    "- 10M.csv\n",
    "\n",
    "- 10M.parquet\n",
    "\n",
    "- airlines.sas7bdat\n",
    "\n",
    "Estos ficheros los podr√©is descargar del [este](https://drive.google.com/drive/folders/1vTvA743_9OjvIk9SX6pdTfhwijGBXlKz) link. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404e218",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919c5cb",
   "metadata": {},
   "source": [
    "## `pd.read_csv()` \n",
    "\n",
    "CSV es el acr√≥nimo de *Comma Separated Values* y significa valores separados por comas. De esta forma, un archivo CSV es cualquier archivo de texto en el cual los caracteres (en nuestro caso las columnas) est√°n separadas por comas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02bdf954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>company_link</th>\n",
       "      <th>experience</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Frontend Developer</td>\n",
       "      <td>mexico</td>\n",
       "      <td>Hacienda San Pablo, M√©xico, Mexico</td>\n",
       "      <td>Vox Feed</td>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>Passion for building interfaces that bring the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>web developer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               title country                            location  \\\n",
       "0   1  Frontend Developer  mexico  Hacienda San Pablo, M√©xico, Mexico   \n",
       "\n",
       "    company        date                                        description  \\\n",
       "0  Vox Feed  2019-08-18  Passion for building interfaces that bring the...   \n",
       "\n",
       "  company_link  experience       keywords  \n",
       "0          NaN           2  web developer  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv(\"files/jobs.csv\")\n",
    "df_csv.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecd5231",
   "metadata": {},
   "source": [
    "Como la propia definici√≥n indica, nuestras columnas deben ir separadas por comas. A veces, puede ocurrir que no vengan separados por comas. Como en el ejemplo que vemos a continuaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dee4f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia;municipio;estacion;magnitud;punto_muestreo;ano;mes;dia;h01;v01;h02;v02;h03;v03;h04;v04;h05;v05;h06;v06;h07;v07;h08;v08;h09;v09;h10;v10;h11;v11;h12;v12;h13;v13;h14;v14;h15;v15;h16;v16;h17;v17;h18;v18;h19;v19;h20;v20;h21;v21;h22;v22;h23;v23;h24;v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28;102;1;1;28102001_1_38;2022;1;30;3;T;3;T;3;T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  provincia;municipio;estacion;magnitud;punto_muestreo;ano;mes;dia;h01;v01;h02;v02;h03;v03;h04;v04;h05;v05;h06;v06;h07;v07;h08;v08;h09;v09;h10;v10;h11;v11;h12;v12;h13;v13;h14;v14;h15;v15;h16;v16;h17;v17;h18;v18;h19;v19;h20;v20;h21;v21;h22;v22;h23;v23;h24;v24\n",
       "0  28;102;1;1;28102001_1_38;2022;1;30;3;T;3;T;3;T...                                                                                                                                                                                                              "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv2 = pd.read_csv(\"files/aire.csv\")\n",
    "df_csv2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58c5a0",
   "metadata": {},
   "source": [
    "Oh oh... Algo ha salido mal... Si nos fijamos nuestras columnas est√°n separadas por `;`. ¬øC√≥mo podemos solucionar esto? \n",
    "\n",
    "> Usando el par√°metro `sep` de `pd.read_csv` donde tendremos que especificar por qu√© est√°n separadas mis columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe52343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia</th>\n",
       "      <th>municipio</th>\n",
       "      <th>estacion</th>\n",
       "      <th>magnitud</th>\n",
       "      <th>punto_muestreo</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>h01</th>\n",
       "      <th>v01</th>\n",
       "      <th>...</th>\n",
       "      <th>h20</th>\n",
       "      <th>v20</th>\n",
       "      <th>h21</th>\n",
       "      <th>v21</th>\n",
       "      <th>h22</th>\n",
       "      <th>v22</th>\n",
       "      <th>h23</th>\n",
       "      <th>v23</th>\n",
       "      <th>h24</th>\n",
       "      <th>v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28102001_1_38</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   provincia  municipio  estacion  magnitud punto_muestreo   ano  mes  dia  \\\n",
       "0         28        102         1         1  28102001_1_38  2022    1   30   \n",
       "\n",
       "   h01 v01  ...  h20 v20  h21 v21  h22 v22  h23 v23  h24 v24  \n",
       "0  3.0   T  ...  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en este caso esta separado por ; \n",
    "\n",
    "df_csv2_1 = pd.read_csv(\"files/aire.csv\", sep = \";\")\n",
    "df_csv2_1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9b1ba",
   "metadata": {},
   "source": [
    "## `pd.read_excel()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3f57f",
   "metadata": {},
   "source": [
    "En este caso abriremos ficheros con extensiones `xls` o `xlsx`. Estos son los documentos de salida de una hoja de c√°lculo de Excel. \n",
    "\n",
    "Los archivos de Excel pueden tener dos extensiones `xls` o `xlsx`, que un archivo tenga una extensi√≥n u otra depende de la versi√≥n de Excel. Versiones anteriores al 2007 ser√°n `xls` y posteriores ser√°n `xlsx`. \n",
    "\n",
    "Independientemente de la extensi√≥n, todos archivos de tipo Excel se abren en Pandas con el m√©todo `pd.read_excel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae3ef902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>espacio_prot_categoria</th>\n",
       "      <th>espacio_prot_figura</th>\n",
       "      <th>espacio_prot_nombre</th>\n",
       "      <th>espacio_prot_superficie_ha</th>\n",
       "      <th>espacio_prot_fecha_declaracion</th>\n",
       "      <th>espacio_prot_normativa</th>\n",
       "      <th>espacio_prot_informacion_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Cuencas Altas de los r√≠os Manzanares, Lozoya y...</td>\n",
       "      <td>105655.000</td>\n",
       "      <td>1992-11-09</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Cuencas Altas de los r√≠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Sierra del Rinc√≥n</td>\n",
       "      <td>15231.000</td>\n",
       "      <td>2005-06-29</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Sierra del Rinc√≥n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Humedal de Importancia Internacional (RAMSAR)</td>\n",
       "      <td>Humedales del Macizo de Pe√±alara</td>\n",
       "      <td>487.198</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Humedales Ramsar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protecci√≥n para las Aves</td>\n",
       "      <td>Monte de El Pardo</td>\n",
       "      <td>15298.670</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protecci√≥n para las Aves</td>\n",
       "      <td>Soto de Vi√±uelas</td>\n",
       "      <td>3071.890</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              espacio_prot_categoria  \\\n",
       "0  √Åreas protegidas por instrumentos internacionales   \n",
       "1  √Åreas protegidas por instrumentos internacionales   \n",
       "2  √Åreas protegidas por instrumentos internacionales   \n",
       "3                Espacios Protegidos Red Natura 2000   \n",
       "4                Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                             espacio_prot_figura  \\\n",
       "0                         Reserva de la Biosfera   \n",
       "1                         Reserva de la Biosfera   \n",
       "2  Humedal de Importancia Internacional (RAMSAR)   \n",
       "3      Zona de Especial Protecci√≥n para las Aves   \n",
       "4      Zona de Especial Protecci√≥n para las Aves   \n",
       "\n",
       "                                 espacio_prot_nombre  \\\n",
       "0  Cuencas Altas de los r√≠os Manzanares, Lozoya y...   \n",
       "1                                  Sierra del Rinc√≥n   \n",
       "2                  Humedales del Macizo de Pe√±alara    \n",
       "3                                  Monte de El Pardo   \n",
       "4                                   Soto de Vi√±uelas   \n",
       "\n",
       "   espacio_prot_superficie_ha espacio_prot_fecha_declaracion  \\\n",
       "0                  105655.000                     1992-11-09   \n",
       "1                   15231.000                     2005-06-29   \n",
       "2                     487.198                     2005-12-16   \n",
       "3                   15298.670                     1988-02-01   \n",
       "4                    3071.890                     1988-02-01   \n",
       "\n",
       "                              espacio_prot_normativa  \\\n",
       "0  Normativa √Åreas protegidas por instrumentos in...   \n",
       "1  Normativa √Åreas protegidas por instrumentos in...   \n",
       "2  Normativa √Åreas protegidas por instrumentos in...   \n",
       "3      Normativa Espacios Protegidos Red Natura 2000   \n",
       "4      Normativa Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                        espacio_prot_informacion_web  \n",
       "0  Reserva de la Biosfera Cuencas Altas de los r√≠...  \n",
       "1           Reserva de la Biosfera Sierra del Rinc√≥n  \n",
       "2                                   Humedales Ramsar  \n",
       "3                Espacios protegidos Red Natura 2000  \n",
       "4                Espacios protegidos Red Natura 2000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel(\"files/espacios_protegidos.xlsx\")\n",
    "df_xlsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d8bf5",
   "metadata": {},
   "source": [
    "üö®‚ö†Ô∏è **SI OS SALE UN ERROR SIMILAR A ESTE:**\n",
    "\n",
    "```\n",
    "ImportError: Missing optional dependency 'openpyxl'. Use pip or conda to install openpyxl.\n",
    "```\n",
    "\n",
    "**DON'T PANIC!!!** Lo √∫nico que tendre√≠s que hacer es importaros `openpyxl`. ¬øC√≥mo? \n",
    "\n",
    "- Nos vamos a la terminal y ejecutamos el siguiente c√≥digo: \n",
    "\n",
    "```\n",
    "pip3 install openpyxl\n",
    "```\n",
    "\n",
    "o \n",
    "\n",
    "```\n",
    "pip install openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a04714",
   "metadata": {},
   "source": [
    "## `pd.read_json()` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f546b6e",
   "metadata": {},
   "source": [
    "Un archivo json (acr√≥nimo de *JavaScript Object Notation*) es un formato para guardar e intercambiar de forma estructurada (principalmente lo hace con una estructura de diccionario) y se utiliza principalmente para transferir datos de un servidor a un cliente. \n",
    "\n",
    "El archivo es b√°sicamente una alternativa m√°s simple y liviana al XML (Lenguaje de marcado extenso, por sus siglas en ingl√©s) que cuenta con funciones similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e9c299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 23476.42, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 1927.25, 'resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 25333.54, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 22060.07, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 13109.74, 'res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  {'residuos_pelig_cantidad_ton': 23476.42, 'res...\n",
       "1  {'residuos_pelig_cantidad_ton': 1927.25, 'resi...\n",
       "2  {'residuos_pelig_cantidad_ton': 25333.54, 'res...\n",
       "3  {'residuos_pelig_cantidad_ton': 22060.07, 'res...\n",
       "4  {'residuos_pelig_cantidad_ton': 13109.74, 'res..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_json = pd.read_json(\"files/residuos.json\")\n",
    "df_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82404269",
   "metadata": {},
   "source": [
    "Pero esto no hay quien lo lea! Pero no os preocupeis, es muy f√°cil de convertir a algo m√°s humano: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d16653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>residuos_pelig_cantidad_ton</th>\n",
       "      <th>residuos_pelig_a√±o</th>\n",
       "      <th>residuos_pelig_opcion_gestion</th>\n",
       "      <th>residuos_pelig_tratamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23476.42</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperaci√≥n de disolventes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927.25</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperaci√≥n de metales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25333.54</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Regeneraci√≥n de aceite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22060.07</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorizaci√≥n</td>\n",
       "      <td>Trituraci√≥n previa a valorizaci√≥n de bater√≠as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109.74</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorizaci√≥n</td>\n",
       "      <td>Operaciones previas a valorizaci√≥n de RAEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   residuos_pelig_cantidad_ton  residuos_pelig_a√±o  \\\n",
       "0                     23476.42                2012   \n",
       "1                      1927.25                2012   \n",
       "2                     25333.54                2012   \n",
       "3                     22060.07                2012   \n",
       "4                     13109.74                2012   \n",
       "\n",
       "                       residuos_pelig_opcion_gestion  \\\n",
       "0                                          Reciclado   \n",
       "1                                          Reciclado   \n",
       "2                                          Reciclado   \n",
       "3  Tratamiento previo a otras formas de valorizaci√≥n   \n",
       "4  Tratamiento previo a otras formas de valorizaci√≥n   \n",
       "\n",
       "                      residuos_pelig_tratamiento  \n",
       "0                    Recuperaci√≥n de disolventes  \n",
       "1                        Recuperaci√≥n de metales  \n",
       "2                         Regeneraci√≥n de aceite  \n",
       "3  Trituraci√≥n previa a valorizaci√≥n de bater√≠as  \n",
       "4     Operaciones previas a valorizaci√≥n de RAEE  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# este c√≥digo no es necesario que lo entendamos ahora, m√°s adelante seg√∫n avancen las lecciones lo iremos entendiendo mejor!\n",
    "df_json2 = df_json['data'].apply(pd.Series)\n",
    "df_json2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676aad0c",
   "metadata": {},
   "source": [
    "## `pd.read_clipboard()`\n",
    "\n",
    "<!-- Nos va a permitir leer el texto del portapapeles y lo pasa a `read_csv`. -->\n",
    "Este m√©todo crea un DataFrame a partir de los datos copiados en el portapapeles. Lee el texto del portapapeles y lo pasa a `read_csv()` que luego devuelve un objeto DataFrame analizado.\n",
    "\n",
    "[Aqu√≠](https://towardsdatascience.com/from-clipboard-to-dataframe-with-pandas-6c212b1d7ed8) teneis un art√≠culo muy interesante para entender esta forma de abrir ficheros \n",
    "\n",
    "Veamos paso a paso como funciona: \n",
    "\n",
    "1Ô∏è‚É£ Abrimos un excel y copiamos su contenido (pod√©is elegir cualquier excel que teng√°is en vuestro ordenador)\n",
    "\n",
    "2Ô∏è‚É£ Vamos a nuestro jupyter y ejecutamos la siguiente l√≠nea de c√≥digo: \n",
    "\n",
    "```python\n",
    "df_clip = pd.read_clipboard()\n",
    "```\n",
    "\n",
    "El par√°metro `sep` nos servir√° para especificar por que est√°n separadas cada fila y columna de nuestra tabla. En nuestro caso est√°n separados por tabulaciones que lo pondremos como `\\t`. En caso de que sea salto de p√°gina lo haremos de la siguiente forma `\\n`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d10bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>espacio_prot_categoria</th>\n",
       "      <th>espacio_prot_figura</th>\n",
       "      <th>espacio_prot_nombre</th>\n",
       "      <th>espacio_prot_superficie_ha</th>\n",
       "      <th>espacio_prot_fecha_declaracion</th>\n",
       "      <th>espacio_prot_normativa</th>\n",
       "      <th>espacio_prot_informacion_web</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Cuencas Altas de los r√≠os Manzanares, Lozoya y...</td>\n",
       "      <td>105655,00</td>\n",
       "      <td>9/11/1992</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Cuencas Altas de los r√≠...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Sierra del Rinc√≥n</td>\n",
       "      <td>15231,00</td>\n",
       "      <td>29/6/2005</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Sierra del Rinc√≥n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              espacio_prot_categoria     espacio_prot_figura  \\\n",
       "0  √Åreas protegidas por instrumentos internacionales  Reserva de la Biosfera   \n",
       "1  √Åreas protegidas por instrumentos internacionales  Reserva de la Biosfera   \n",
       "\n",
       "                                 espacio_prot_nombre  \\\n",
       "0  Cuencas Altas de los r√≠os Manzanares, Lozoya y...   \n",
       "1                                  Sierra del Rinc√≥n   \n",
       "\n",
       "  espacio_prot_superficie_ha espacio_prot_fecha_declaracion  \\\n",
       "0                  105655,00                      9/11/1992   \n",
       "1                   15231,00                      29/6/2005   \n",
       "\n",
       "                              espacio_prot_normativa  \\\n",
       "0  Normativa √Åreas protegidas por instrumentos in...   \n",
       "1  Normativa √Åreas protegidas por instrumentos in...   \n",
       "\n",
       "                        espacio_prot_informacion_web  Unnamed: 7  Unnamed: 8  \\\n",
       "0  Reserva de la Biosfera Cuencas Altas de los r√≠...         NaN         NaN   \n",
       "1           Reserva de la Biosfera Sierra del Rinc√≥n         NaN         NaN   \n",
       "\n",
       "   Unnamed: 9  ...  Unnamed: 16  Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
       "0         NaN  ...          NaN          NaN          NaN          NaN   \n",
       "1         NaN  ...          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  Unnamed: 24  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 25  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clipboard = pd.read_clipboard(sep='\\t')\n",
    "df_clipboard.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2ee3203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia</th>\n",
       "      <th>municipio</th>\n",
       "      <th>estacion</th>\n",
       "      <th>magnitud</th>\n",
       "      <th>punto_muestreo</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>h01</th>\n",
       "      <th>v01</th>\n",
       "      <th>...</th>\n",
       "      <th>h20</th>\n",
       "      <th>v20</th>\n",
       "      <th>h21</th>\n",
       "      <th>v21</th>\n",
       "      <th>h22</th>\n",
       "      <th>v22</th>\n",
       "      <th>h23</th>\n",
       "      <th>v23</th>\n",
       "      <th>h24</th>\n",
       "      <th>v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28102001_1_38</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>28102001_6_48</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   provincia  municipio  estacion  magnitud punto_muestreo   ano  mes  dia  \\\n",
       "0         28        102         1         1  28102001_1_38  2022    1   30   \n",
       "1         28        102         1         6  28102001_6_48  2022    1   30   \n",
       "\n",
       "   h01 v01  ...  h20 v20  h21 v21  h22 v22  h23 v23  h24 v24  \n",
       "0  3.0   T  ...  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  \n",
       "1  0.2   T  ...  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  \n",
       "\n",
       "[2 rows x 56 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lo mismo podemos hacer con un csv\n",
    "\n",
    "df_clipboard2 = pd.read_clipboard(sep=';')\n",
    "df_clipboard2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e3ab625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>Marks_scored</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>sub1</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>sub2</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Name subject_id  Marks_scored  Rank\n",
       "0   1  Alex       sub1            98     1\n",
       "1   2   Amy       sub2            90     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clipboard3 = pd.read_clipboard()\n",
    "df_clipboard3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a46028",
   "metadata": {},
   "source": [
    "üö® Tambi√©n lo podremos hacer datos de p√°ginas webs üîù!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ecbfa",
   "metadata": {},
   "source": [
    "## `pd.read_pickle()` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37872443",
   "metadata": {},
   "source": [
    "Pickle (acr√≥nimo de *Python Pickle Format*) que fue desarrollado por Python. \n",
    "\n",
    "¬øQu√© es Pickle exactamente?\n",
    "\n",
    "En Python, puede usar el pickle m√≥dulo para serializar objetos y guardarlos en un archivo. \n",
    "\n",
    "Pickle tiene una gran ventaja sobre otros formatos: puede usarlo para almacenar cualquier objeto de Python, como diccionarios, pandas, arrays, etc. Una de las funcionalidades m√°s utilizadas es guardar los modelos de *machine learning*. De esa manera, no tiene que volver a capacitar al modelo cada vez que ejecuta el script.\n",
    "\n",
    "Tambi√©n se puede usar Pickle para almacenar matrices Numpy. Es una soluci√≥n obvia para establecer puntos de control de alg√∫n tipo en su c√≥digo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea3bbf",
   "metadata": {},
   "source": [
    "¬øC√≥mo trabajar con Pickle en Python? üëáüèΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da2a9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que vamos a hacer es crearnos un dataframe\n",
    "\n",
    "df_size = 10000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': np.random.rand(df_size),\n",
    "    'b': np.random.rand(df_size),\n",
    "    'c': np.random.rand(df_size),\n",
    "    'd': np.random.rand(df_size),\n",
    "    'e': np.random.rand(df_size)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e71fc647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833498</td>\n",
       "      <td>0.847162</td>\n",
       "      <td>0.868753</td>\n",
       "      <td>0.886461</td>\n",
       "      <td>0.689088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.929106</td>\n",
       "      <td>0.407155</td>\n",
       "      <td>0.733652</td>\n",
       "      <td>0.791978</td>\n",
       "      <td>0.425729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509469</td>\n",
       "      <td>0.694968</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>0.389690</td>\n",
       "      <td>0.612029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.651677</td>\n",
       "      <td>0.260642</td>\n",
       "      <td>0.661609</td>\n",
       "      <td>0.506463</td>\n",
       "      <td>0.448491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.728739</td>\n",
       "      <td>0.069496</td>\n",
       "      <td>0.124216</td>\n",
       "      <td>0.728842</td>\n",
       "      <td>0.717674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e\n",
       "0  0.833498  0.847162  0.868753  0.886461  0.689088\n",
       "1  0.929106  0.407155  0.733652  0.791978  0.425729\n",
       "2  0.509469  0.694968  0.008364  0.389690  0.612029\n",
       "3  0.651677  0.260642  0.661609  0.506463  0.448491\n",
       "4  0.728739  0.069496  0.124216  0.728842  0.717674"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43fb431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ¬µs, sys: 0 ns, total: 2 ¬µs\n",
      "Wall time: 5.25 ¬µs\n"
     ]
    }
   ],
   "source": [
    "# guardemoslo localmente \n",
    "%time # comando m√°gico que nos devuelve el tiempo que tarda en ejecutarse nuestro c√≥digo\n",
    "\n",
    "with open('files/10M.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcca84",
   "metadata": {},
   "source": [
    "Si ahora vamos a nuestra carpeta veremos que tenemos un nuevo fichero que se llama `10M.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12e9a19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ¬µs, sys: 1e+03 ns, total: 3 ¬µs\n",
      "Wall time: 4.05 ¬µs\n"
     ]
    }
   ],
   "source": [
    "# lo guardaremos tambi√©n como csv para ver que se carga m√°s r√°pido\n",
    "%time\n",
    "df.to_csv('files/10M.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27a6d4",
   "metadata": {},
   "source": [
    "**CSV frente a Pickle: ¬øcu√°l deber√≠a usar?**\n",
    "\n",
    "Responder esta pregunta no es tan f√°cil como parece. Claro, los CSV brindan privilegios de visualizaci√≥n y edici√≥n, ya que cualquiera puede abrirlos. Eso tambi√©n podr√≠a considerarse una desventaja, por razones obvias. Adem√°s, no puede guardar modelos de aprendizaje autom√°tico en un archivo CSV.\n",
    "\n",
    "A√∫n as√≠, comparemos los dos en tama√±o de archivo, tiempos de lectura y escritura.\n",
    "\n",
    "- pickle es mucho m√°s r√°pido que el csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cbb83f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ¬µs, sys: 0 ns, total: 3 ¬µs\n",
      "Wall time: 6.44 ¬µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833498</td>\n",
       "      <td>0.847162</td>\n",
       "      <td>0.868753</td>\n",
       "      <td>0.886461</td>\n",
       "      <td>0.689088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.929106</td>\n",
       "      <td>0.407155</td>\n",
       "      <td>0.733652</td>\n",
       "      <td>0.791978</td>\n",
       "      <td>0.425729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e\n",
       "0  0.833498  0.847162  0.868753  0.886461  0.689088\n",
       "1  0.929106  0.407155  0.733652  0.791978  0.425729"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "pd.read_pickle(\"files/10M.pkl\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c55a6363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ¬µs, sys: 1e+03 ns, total: 3 ¬µs\n",
      "Wall time: 5.48 ¬µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833498</td>\n",
       "      <td>0.847162</td>\n",
       "      <td>0.868753</td>\n",
       "      <td>0.886461</td>\n",
       "      <td>0.689088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.929106</td>\n",
       "      <td>0.407155</td>\n",
       "      <td>0.733652</td>\n",
       "      <td>0.791978</td>\n",
       "      <td>0.425729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e\n",
       "0  0.833498  0.847162  0.868753  0.886461  0.689088\n",
       "1  0.929106  0.407155  0.733652  0.791978  0.425729"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "pd.read_csv(\"files/10M.csv\", index_col = 0).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b8246",
   "metadata": {},
   "source": [
    "Aunque parece poco, el pickle se ha cargado mucho m√°s r√°pido que el csv. Imaginad como se puede notar esto cuando tengamos millones de datos! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6b06c",
   "metadata": {},
   "source": [
    "## `pd.read_parquet()`\n",
    "\n",
    "Los formatos de archivo para el intercambio de datos m√°s populares actualmente son CSV y Microsoft Excel. Este tipo de archivos pueden ser poco eficientes a la hora trabajar con grandes conjuntos de datos.\n",
    "\n",
    "Como hemos visto CSV es un formato basado en archivos de texto plano, lo que permite su edici√≥n con cualquier editor de texto, sin la necesidad de emplear un programa espec√≠fico. Aunque esto tambi√©n se traduce en archivos de gran tama√±o y cuyo proceso es lento. \n",
    "\n",
    "Por otro lado, Microsoft Excel es un formato dise√±ado para trabajar con hojas de c√°lculo.\n",
    "\n",
    "Actualmente, para poder trabajar de forma eficiente con grandes conjuntos de datos, se han dise√±ado nuevos formatos como Parquet que ofrece archivos m√°s peque√±os, lo que ofrece importantes ahorros a la hora de almacenar los datos, y cuyas operaciones de lectura y escritura son tambi√©n m√°s r√°pidas, lo que reduce el tiempo de procesado.\n",
    "\n",
    "Apache Parquet es un formato de archivo para el almacenamiento de datos orientado a columnas de c√≥digo abierto del ecosistema Apache Hadoop. Por lo que es compatible con la mayor√≠a de *frameworks* para el procesado de datos. En este formato, los valores de cada columna se almacenan f√≠sicamente en posiciones contiguas, lo que consigue que la compresi√≥n de los datos sea m√°s eficiente al ser los datos contiguos similares. Permitiendo adem√°s usar diferentes t√©cnicas de compresi√≥n para cada columna, pudiendo adaptar esta al tipo de dato.\n",
    "\n",
    "**Parquet en Pandas**\n",
    "\n",
    "Pandas cuenta con herramientas para trabajar con archivos Parquet, por lo que no es necesario importar ning√∫n paquete adicional. Para importar archivos Parquet en objetos *DataFrame* de Pandas se puede recurrir a la funci√≥n `read_parquet()`, la cual funciona de manera similar a otras funciones `como read_csv()`. Adem√°s de esto los objetos DataFrame cuenta con la propiedad `to_parquet()`, con la que es posible volcar cualquier conjunto de datos en un archivo Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57326bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ¬µs, sys: 1e+03 ns, total: 4 ¬µs\n",
      "Wall time: 11.4 ¬µs\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m'\u001b[39;49m\u001b[39mfiles/10M.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39mDataFrame\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    501\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    504\u001b[0m     path,\n\u001b[1;32m    505\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    506\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    507\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[1;32m    508\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    509\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py:251\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    245\u001b[0m     path,\n\u001b[1;32m    246\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[1;32m    248\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mparquet\u001b[39m.\u001b[39;49mread_table(\n\u001b[1;32m    252\u001b[0m         path_or_handle, columns\u001b[39m=\u001b[39;49mcolumns, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    253\u001b[0m     )\u001b[39m.\u001b[39mto_pandas(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    255\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m_as_manager(\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyarrow/parquet/core.py:2824\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2817\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2818\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m keyword is no longer supported with the new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2819\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdatasets-based implementation. Specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2820\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39muse_legacy_dataset=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to temporarily recover the old \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2821\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbehaviour.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2822\u001b[0m     )\n\u001b[1;32m   2823\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2824\u001b[0m     dataset \u001b[39m=\u001b[39m _ParquetDatasetV2(\n\u001b[1;32m   2825\u001b[0m         source,\n\u001b[1;32m   2826\u001b[0m         schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   2827\u001b[0m         filesystem\u001b[39m=\u001b[39;49mfilesystem,\n\u001b[1;32m   2828\u001b[0m         partitioning\u001b[39m=\u001b[39;49mpartitioning,\n\u001b[1;32m   2829\u001b[0m         memory_map\u001b[39m=\u001b[39;49mmemory_map,\n\u001b[1;32m   2830\u001b[0m         read_dictionary\u001b[39m=\u001b[39;49mread_dictionary,\n\u001b[1;32m   2831\u001b[0m         buffer_size\u001b[39m=\u001b[39;49mbuffer_size,\n\u001b[1;32m   2832\u001b[0m         filters\u001b[39m=\u001b[39;49mfilters,\n\u001b[1;32m   2833\u001b[0m         ignore_prefixes\u001b[39m=\u001b[39;49mignore_prefixes,\n\u001b[1;32m   2834\u001b[0m         pre_buffer\u001b[39m=\u001b[39;49mpre_buffer,\n\u001b[1;32m   2835\u001b[0m         coerce_int96_timestamp_unit\u001b[39m=\u001b[39;49mcoerce_int96_timestamp_unit,\n\u001b[1;32m   2836\u001b[0m         thrift_string_size_limit\u001b[39m=\u001b[39;49mthrift_string_size_limit,\n\u001b[1;32m   2837\u001b[0m         thrift_container_size_limit\u001b[39m=\u001b[39;49mthrift_container_size_limit,\n\u001b[1;32m   2838\u001b[0m     )\n\u001b[1;32m   2839\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m   2840\u001b[0m     \u001b[39m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[1;32m   2841\u001b[0m     \u001b[39m# module is not available\u001b[39;00m\n\u001b[1;32m   2842\u001b[0m     \u001b[39mif\u001b[39;00m filters \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyarrow/parquet/core.py:2412\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[39mif\u001b[39;00m single_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2409\u001b[0m     fragment \u001b[39m=\u001b[39m parquet_format\u001b[39m.\u001b[39mmake_fragment(single_file, filesystem)\n\u001b[1;32m   2411\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mFileSystemDataset(\n\u001b[0;32m-> 2412\u001b[0m         [fragment], schema\u001b[39m=\u001b[39mschema \u001b[39mor\u001b[39;00m fragment\u001b[39m.\u001b[39;49mphysical_schema,\n\u001b[1;32m   2413\u001b[0m         \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mparquet_format,\n\u001b[1;32m   2414\u001b[0m         filesystem\u001b[39m=\u001b[39mfragment\u001b[39m.\u001b[39mfilesystem\n\u001b[1;32m   2415\u001b[0m     )\n\u001b[1;32m   2416\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   2418\u001b[0m \u001b[39m# check partitioning to enable dictionary encoding\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyarrow/_dataset.pyx:905\u001b[0m, in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
     ]
    }
   ],
   "source": [
    "%time\n",
    "pd.read_parquet('files/10M.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89854b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/pfuente/anaconda3/lib/python3.9/site-packages (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from pyarrow) (1.23.5)\n",
      "Requirement already satisfied: fastparquet in /home/pfuente/anaconda3/lib/python3.9/site-packages (2022.11.0)\n",
      "Requirement already satisfied: packaging in /home/pfuente/anaconda3/lib/python3.9/site-packages (from fastparquet) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from fastparquet) (1.23.5)\n",
      "Requirement already satisfied: cramjam>=2.3 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from fastparquet) (2.6.2)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from fastparquet) (1.5.2)\n",
      "Requirement already satisfied: fsspec in /home/pfuente/anaconda3/lib/python3.9/site-packages (from fastparquet) (2022.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from pandas>=1.5.0->fastparquet) (2022.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from packaging->fastparquet) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Requirement already satisfied: pandas in /home/pfuente/anaconda3/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from pandas) (2022.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/pfuente/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n",
    "!pip install fastparquet\n",
    "!pip3 install --upgrade pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc118dd",
   "metadata": {},
   "source": [
    "**Diferencias entre `csv`, `pickle` y `parquet`**\n",
    "\n",
    "- `CSV`\n",
    "\n",
    "‚úÖ lectura humana  \n",
    "‚úÖ en todas las plataformas  \n",
    "‚õî m√°s lento  \n",
    "‚õî m√°s espacio en disco  \n",
    "‚õî no conserva los tipos en algunos casos  \n",
    "\n",
    "\n",
    "- `PICKLE`\n",
    "\n",
    "‚úÖ guardado/carga r√°pida  \n",
    "‚úÖ menos espacio en disco  \n",
    "‚õî no es legible para las personas  \n",
    "‚õî s√≥lo para python  \n",
    "\n",
    "- `PARQUET`: \n",
    "\n",
    "‚úÖ guardado/carga r√°pida  \n",
    "‚úÖ menos espacio en disco que pickle  \n",
    "‚úÖ suportado por muchas plataformas  \n",
    "‚õî es menos legible para los humanos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335db5c",
   "metadata": {},
   "source": [
    "## `pd.read_sas()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f1387",
   "metadata": {},
   "source": [
    "Lee archivos SAS almacenados en formato XPORT o SAS7BDAT.\n",
    "\n",
    "SAS es uno de los sistemas de an√°lisis avanzados m√°s populares, utilizado por muchas grandes empresas desde hace d√©cadas. Si queremos realizar alg√∫n an√°lisis utilizando un conjunto de datos SAS existente (un archivo de datos en SAS), podemos leer en Python utilizando la funci√≥n `read_sas`.\n",
    "\n",
    "`read_sas()` toma unos pocos argumentos (la mayor√≠a de ellos viene con valores predefinidos que puedes alterar si es necesario). El √∫nico obligatorio es `file_path`. \n",
    "\n",
    "La sintaxis con los par√°metros m√°s importantes es: \n",
    "\n",
    "```python\n",
    "pd.read_sas(nombre_fichero, format=None)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "\n",
    "- `nombre_fichero`: el nombre del fichero o el path al fichero. \n",
    "\n",
    "\n",
    "- `format`: por defecto None. \n",
    "\n",
    "    - Si es None, el formato del archivo se deduce de la extensi√≥n del mismo. \n",
    "    \n",
    "    - Si es 'xport' o 'sas7bdat', utiliza el formato correspondiente.\n",
    "\n",
    "    \n",
    "\n",
    "[Aqu√≠](https://haven.tidyverse.org/reference/read_sas.html) ten√©is m√°s informaci√≥n sobre este m√©todo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7469228b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Y</th>\n",
       "      <th>W</th>\n",
       "      <th>R</th>\n",
       "      <th>L</th>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948.0</td>\n",
       "      <td>1.214</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>1.415</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949.0</td>\n",
       "      <td>1.354</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>1.384</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR      Y      W       R      L      K\n",
       "0  1948.0  1.214  0.243  0.1454  1.415  0.612\n",
       "1  1949.0  1.354  0.260  0.2181  1.384  0.559"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sas('files/airline.sas7bdat', format = 'sas7bdat').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b7e4f",
   "metadata": {},
   "source": [
    "## `pd.read_spss()`\n",
    "\n",
    "SPSS es un formato que ofrece IBM para un an√°lisis completo. Es el acr√≥nimo de Producto de Estad√≠stica y Soluci√≥n de Servicio. SPSS se utiliza para una amplia gama de an√°lisis estad√≠sticos, como las estad√≠sticas descriptivas (por ejemplo medias, frecuencias), las estad√≠sticas bivariadas (por ejemplo an√°lisis de la varianza, prueba t), regresi√≥n, el an√°lisis de factores, y la representaci√≥n gr√°fica de los datos.\n",
    "\n",
    "\n",
    "Este tipo de archivos es com√∫n en el √°mbito de la investigaci√≥n de mercados. A menudo √©stos est√°n disponibles como archivos SAV o SPSS. SPSS es ideal para el an√°lisis estad√≠stico de datos de encuestas porque las variables, las etiquetas de las variables, los valores y las etiquetas de los valores est√°n integrados en un conjunto de datos.\n",
    "\n",
    "Desafortunadamente, SPSS es lento en sets de datos grandes y el sistema de macros para la automatizaci√≥n no es intuitivo y ofrece s√≥lo unas pocas opciones en comparaci√≥n con Python. Por lo tanto, no ser√° un tipo de archivo que nos encontremos habitualmente. \n",
    "\n",
    "`read_spss()` lee los datos de un archivo almacenado en formato SPSS `*.sav`. \n",
    "\n",
    "Devuelve un *DataFrame* y **nunca** convierte las variables de tipo *string* en factores. Tambi√©n prepara las etiquetas de los valores/variables de SPSS para trabajar con las funciones `val_lab`/`var_lab`. \n",
    "\n",
    "Ignora los valores nulos. \n",
    "\n",
    "Su sintaxis: \n",
    "\n",
    "```python\n",
    "pd.read_spss(path, usecols=None, convert_categoricals=True)\n",
    "```\n",
    "\n",
    "Donde : \n",
    "\n",
    "- `path`: *string* ruta a nuestro archivo. \n",
    "\n",
    "- `usecols`: lista, opcional. Devuelve un subconjunto de las columnas. Si es `None`, devuelve todas las columnas.\n",
    "\n",
    "- `convert_categoricals`: booleano, por defecto es `True`. Convierte las columnas categ√≥ricas en `pd.Categorical`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef78f94",
   "metadata": {},
   "source": [
    "# üìå Nota importante al leer archivos: \n",
    "\n",
    "Varias cosas pueden ir mal cuando se importan los datos a Pandas. Algunos de ellos son inmediatamente obvios; otros s√≥lo aparecen m√°s tarde, en formas confusas.\n",
    "\n",
    "En este apartado veremos uno de los problemas m√°s comunes al cargar datos en Pandas - la codificaci√≥n de texto.\n",
    "\n",
    "Las codificaciones de texto son conjuntos espec√≠ficos de reglas para mapear desde cadenas de bytes binarios sin procesar hasta caracteres que componen el texto legible por humanos. Python tiene soporte integrado para una lista de codificaciones est√°ndar.\n",
    "\n",
    "Las discrepancias en la codificaci√≥n de caracteres son menos comunes hoy en d√≠a, ya que UTF-8 es la codificaci√≥n de texto est√°ndar en la mayor√≠a de los lenguajes de programaci√≥n, incluido Python. Sin embargo, definitivamente sigue siendo un problema si estamos intentando leer un archivo con una codificaci√≥n diferente a la que se escribi√≥ originalmente.\n",
    "\n",
    "Otra codificaci√≥n com√∫n, pero menos √∫til, es la llamada Latin 1 o ISO-8859-1. Esta codificaci√≥n s√≥lo define formas de representar los caracteres del texto en el alfabeto latino est√°ndar. Se trata del alfabeto ingl√©s est√°ndar m√°s una serie de caracteres de otras lenguas europeas, incluidos los caracteres con acento.\n",
    "\n",
    "La funci√≥n `read_csv()` de Pandas tiene una llamada de argumento `encoding` que le permite especificar una codificaci√≥n para usar al leer un archivo. Pandas asume que el texto est√° en formato UTF-8, porque es el m√°s com√∫n.\n",
    "\n",
    "Os dejamos [aqu√≠](https://docs.python.org/3/library/codecs.html#standard-encodings) una lista con los principales tipos de *encoding* que podemos encontrarnos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5852b3c",
   "metadata": {},
   "source": [
    "# Guardado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62096d27",
   "metadata": {},
   "source": [
    "Imaginemos ahora que hemos hecho algunos cambios en nuestro dataframe, por ejemplo quitar algunas columnas y que queremos guardar los cambios en nuestro ordenador. Pandas nos lo va a permitir para cada uno de los tipos de archivos que hemos estado viendo hasta ahora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064f6eb",
   "metadata": {},
   "source": [
    "`to_csv`: guardaremos el archivo en formato csv. Normalmente con especificar el directorio y el nombre del fichero ser√° suficiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07d3a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en csv\n",
    "\n",
    "df_csv2.to_csv(\"datos/datos_sincolumna.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4d555d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en formato de excel\n",
    "\n",
    "df_csv2.to_excel(\"datos/datos_sincolumna.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e144058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en formato json\n",
    "\n",
    "df_csv2.to_json(\"datos/datos_sincolumna.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "524773a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en formato parquet\n",
    "\n",
    "df_csv2.to_parquet(\"datos/datos_sincolumna.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5c27772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en formato pickle\n",
    "\n",
    "df_csv2.to_pickle(\"datos/datos_sincolumna.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cccea3",
   "metadata": {},
   "source": [
    "Aqu√≠ os dejamos algo de documentaci√≥n m√°s detallada de cada uno de los m√©todos: \n",
    "\n",
    "- [to_csv](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n",
    "\n",
    "- [to_excel](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html)\n",
    "\n",
    "- [to_json](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html)\n",
    "\n",
    "- [to_parquet](https://pandas.pydata.org/pandas-docs/version/1.1/reference/api/pandas.DataFrame.to_parquet.html)\n",
    "\n",
    "- [to_pickle](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26bec5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ¬µs, sys: 1 ¬µs, total: 3 ¬µs\n",
      "Wall time: 5.25 ¬µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia;municipio;estacion;magnitud;punto_muestreo;ano;mes;dia;h01;v01;h02;v02;h03;v03;h04;v04;h05;v05;h06;v06;h07;v07;h08;v08;h09;v09;h10;v10;h11;v11;h12;v12;h13;v13;h14;v14;h15;v15;h16;v16;h17;v17;h18;v18;h19;v19;h20;v20;h21;v21;h22;v22;h23;v23;h24;v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28;102;1;1;28102001_1_38;2022;1;30;3;T;3;T;3;T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28;102;1;6;28102001_6_48;2022;1;30;0.2;T;0.1;T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28;102;1;7;28102001_7_8;2022;1;30;1;T;1;T;1;T;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28;102;1;8;28102001_8_8;2022;1;30;6;T;5;T;5;T;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28;102;1;10;28102001_10_49;2022;1;30;3;T;5;T;6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>28;92;5;7;28092005_7_8;2022;1;30;90;T;29;T;17;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>28;92;5;8;28092005_8_8;2022;1;30;100;T;78;T;65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>28;92;5;10;28092005_10_49;2022;1;30;34;T;44;T;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>28;92;5;12;28092005_12_8;2022;1;30;237;T;122;T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>28;92;5;14;28092005_14_6;2022;1;30;1;T;7;T;14;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    provincia;municipio;estacion;magnitud;punto_muestreo;ano;mes;dia;h01;v01;h02;v02;h03;v03;h04;v04;h05;v05;h06;v06;h07;v07;h08;v08;h09;v09;h10;v10;h11;v11;h12;v12;h13;v13;h14;v14;h15;v15;h16;v16;h17;v17;h18;v18;h19;v19;h20;v20;h21;v21;h22;v22;h23;v23;h24;v24\n",
       "0    28;102;1;1;28102001_1_38;2022;1;30;3;T;3;T;3;T...                                                                                                                                                                                                              \n",
       "1    28;102;1;6;28102001_6_48;2022;1;30;0.2;T;0.1;T...                                                                                                                                                                                                              \n",
       "2    28;102;1;7;28102001_7_8;2022;1;30;1;T;1;T;1;T;...                                                                                                                                                                                                              \n",
       "3    28;102;1;8;28102001_8_8;2022;1;30;6;T;5;T;5;T;...                                                                                                                                                                                                              \n",
       "4    28;102;1;10;28102001_10_49;2022;1;30;3;T;5;T;6...                                                                                                                                                                                                              \n",
       "..                                                 ...                                                                                                                                                                                                              \n",
       "155  28;92;5;7;28092005_7_8;2022;1;30;90;T;29;T;17;...                                                                                                                                                                                                              \n",
       "156  28;92;5;8;28092005_8_8;2022;1;30;100;T;78;T;65...                                                                                                                                                                                                              \n",
       "157  28;92;5;10;28092005_10_49;2022;1;30;34;T;44;T;...                                                                                                                                                                                                              \n",
       "158  28;92;5;12;28092005_12_8;2022;1;30;237;T;122;T...                                                                                                                                                                                                              \n",
       "159  28;92;5;14;28092005_14_6;2022;1;30;1;T;7;T;14;...                                                                                                                                                                                                              \n",
       "\n",
       "[160 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "pd.read_parquet('datos/datos_sincolumna.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "85c042135e83639dad74b6ec6c9d943b5dc47ca281624d931a3e14168052f53c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
